{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import imagecodecs\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------------------------------\n",
    "PATCH_SIZE = 256\n",
    "STRIDE = PATCH_SIZE\n",
    "\n",
    "# --- Input (original) dataset ---\n",
    "ORIG_DATA_DIR = \"/Users/celinewu/Documents/2024_dataset\"\n",
    "IMG_DIR = os.path.join(ORIG_DATA_DIR, \"images\")\n",
    "MASK_DIR = os.path.join(ORIG_DATA_DIR, \"masks\")\n",
    "\n",
    "# --- Output (processed) dataset ---\n",
    "OUT_DATA_DIR = \"/Users/celinewu/Documents/dataset_patches\"\n",
    "\n",
    "# Subfolders for images\n",
    "OUT_IMG_TRAIN = os.path.join(OUT_DATA_DIR, \"images\", \"train\")\n",
    "OUT_IMG_TEST = os.path.join(OUT_DATA_DIR, \"images\", \"val\")\n",
    "\n",
    "# Subfolders for masks\n",
    "OUT_MASK_TRAIN = os.path.join(OUT_DATA_DIR, \"masks\", \"train\")\n",
    "OUT_MASK_TEST = os.path.join(OUT_DATA_DIR, \"masks\", \"val\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(OUT_IMG_TRAIN, exist_ok=True)\n",
    "os.makedirs(OUT_IMG_TEST, exist_ok=True)\n",
    "os.makedirs(OUT_MASK_TRAIN, exist_ok=True)\n",
    "os.makedirs(OUT_MASK_TEST, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# SPECIFIC IMAGES TO FORCE INTO TRAIN\n",
    "# ----------------------------------------------------------------\n",
    "force_train = [\n",
    "    \"train_Shival_211066\", \"train_Shival_230036\", \"train_Shival_230306\",\n",
    "    \"train_Shival_231007\", \"train_Shival_231265\", \"train_Shival_231781\",\n",
    "    \"train_Shival_232166\", \"train_Shival_232374\", \"train_Shival_233182\",\n",
    "    \"train_Shival_234275\", \"train_Shival_234803\", \"train_Shival_234924\",\n",
    "    \"train_Shival_235065\"\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# ----------------------------------------------------------------\n",
    "def pad_to_multiple(img, multiple=256, border_mode=cv2.BORDER_REFLECT):\n",
    "    h, w = img.shape[:2]\n",
    "    pad_h = (multiple - (h % multiple)) if (h % multiple) != 0 else 0\n",
    "    pad_w = (multiple - (w % multiple)) if (w % multiple) != 0 else 0\n",
    "    return cv2.copyMakeBorder(img, 0, pad_h, 0, pad_w, border_mode)\n",
    "\n",
    "\n",
    "def split_into_patches(img, patch_size=256, stride=256):\n",
    "    h, w = img.shape[:2]\n",
    "    patches = []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            patch = img[y:y+patch_size, x:x+patch_size]\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def save_image_patch(patch, out_path):\n",
    "    cv2.imwrite(out_path, patch)\n",
    "\n",
    "\n",
    "def save_mask_patch(patch, out_path):\n",
    "    tifffile.imwrite(out_path, patch)\n",
    "\n",
    "\n",
    "def process_one_image(img_path, is_train=True):\n",
    "    base_name = os.path.basename(img_path)\n",
    "    file_no_ext = os.path.splitext(base_name)[0]\n",
    "\n",
    "    # Determine output folders\n",
    "    if is_train:\n",
    "        out_img_folder = OUT_IMG_TRAIN\n",
    "        out_mask_folder = OUT_MASK_TRAIN\n",
    "    else:\n",
    "        out_img_folder = OUT_IMG_TEST\n",
    "        out_mask_folder = OUT_MASK_TEST\n",
    "\n",
    "    # Extract identifier\n",
    "    identifier = \"_\".join(file_no_ext.split(\"_\")[-2:])\n",
    "\n",
    "    # Build corresponding mask paths\n",
    "    root_path = os.path.join(MASK_DIR, f\"{file_no_ext}_root_mask.tif\")\n",
    "    shoot_path = os.path.join(MASK_DIR, f\"{file_no_ext}_shoot_mask.tif\")\n",
    "    seed_path = os.path.join(MASK_DIR, f\"{file_no_ext}_seed_mask.tif\")\n",
    "\n",
    "    # Read image and masks\n",
    "    img_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        print(f\"[ERROR] Cannot read image: {img_path}\")\n",
    "        return\n",
    "\n",
    "    mask_root = tifffile.imread(root_path) if os.path.exists(root_path) else None\n",
    "    mask_shoot = tifffile.imread(shoot_path) if os.path.exists(shoot_path) else None\n",
    "    mask_seed = tifffile.imread(seed_path) if os.path.exists(seed_path) else None\n",
    "\n",
    "    # Pad image and masks\n",
    "    padded_img = pad_to_multiple(img_bgr, PATCH_SIZE)\n",
    "    padded_root = pad_to_multiple(mask_root, PATCH_SIZE) if mask_root is not None else None\n",
    "    padded_shoot = pad_to_multiple(mask_shoot, PATCH_SIZE) if mask_shoot is not None else None\n",
    "    padded_seed = pad_to_multiple(mask_seed, PATCH_SIZE) if mask_seed is not None else None\n",
    "\n",
    "    # Split into patches\n",
    "    img_patches = split_into_patches(padded_img, PATCH_SIZE, STRIDE)\n",
    "    root_patches = split_into_patches(padded_root, PATCH_SIZE, STRIDE) if padded_root is not None else [None] * len(img_patches)\n",
    "    shoot_patches = split_into_patches(padded_shoot, PATCH_SIZE, STRIDE) if padded_shoot is not None else [None] * len(img_patches)\n",
    "    seed_patches = split_into_patches(padded_seed, PATCH_SIZE, STRIDE) if padded_seed is not None else [None] * len(img_patches)\n",
    "\n",
    "    # Save patches\n",
    "    for idx, img_patch in enumerate(img_patches):\n",
    "        patch_name_img = f\"{identifier}_patch{idx}.png\"\n",
    "        out_img_path = os.path.join(out_img_folder, patch_name_img)\n",
    "        save_image_patch(img_patch, out_img_path)\n",
    "\n",
    "        if root_patches[idx] is not None:\n",
    "            save_mask_patch(root_patches[idx], os.path.join(out_mask_folder, f\"{identifier}_root_patch{idx}.tif\"))\n",
    "        if shoot_patches[idx] is not None:\n",
    "            save_mask_patch(shoot_patches[idx], os.path.join(out_mask_folder, f\"{identifier}_shoot_patch{idx}.tif\"))\n",
    "        if seed_patches[idx] is not None:\n",
    "            save_mask_patch(seed_patches[idx], os.path.join(out_mask_folder, f\"{identifier}_seed_patch{idx}.tif\"))\n",
    "\n",
    "    print(f\"[OK] Completed patches for {base_name} -> {'train' if is_train else 'test'} folder.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# DATASET PROCESSING FUNCTION\n",
    "# ----------------------------------------------------------------\n",
    "def process_dataset_by_image():\n",
    "    \"\"\"\n",
    "    Splits dataset into train and test based on filenames, processes each image.\n",
    "    \"\"\"\n",
    "    # Gather all PNG images in the dataset\n",
    "    image_paths = glob.glob(os.path.join(IMG_DIR, \"*.png\"))\n",
    "    image_paths.sort()\n",
    "\n",
    "    # Explicitly assign specific files to train\n",
    "    train_image_paths = [\n",
    "        path for path in image_paths if \"train\" in os.path.basename(path).lower()\n",
    "    ]\n",
    "\n",
    "    # Add force_train images to train_image_paths (avoid duplicates)\n",
    "    train_image_paths += [\n",
    "        path for path in image_paths \n",
    "        if any(force in os.path.basename(path) for force in force_train) \n",
    "        and path not in train_image_paths\n",
    "    ]\n",
    "\n",
    "    # Ensure test images include only \"val\" and exclude those forced into train\n",
    "    test_image_paths = [\n",
    "        path for path in image_paths\n",
    "        if path not in train_image_paths and \"val\" in os.path.basename(path).lower()\n",
    "    ]\n",
    "\n",
    "    # Print preview of train and test splits\n",
    "    print(f\"Total images: {len(image_paths)}\")\n",
    "    print(f\"Train images ({len(train_image_paths)}):\")\n",
    "    for path in train_image_paths:\n",
    "        print(f\" - {os.path.basename(path)}\")\n",
    "\n",
    "    print(f\"Test images ({len(test_image_paths)}):\")\n",
    "    for path in test_image_paths:\n",
    "        print(f\" - {os.path.basename(path)}\")\n",
    "\n",
    "    # Prompt for confirmation before proceeding\n",
    "    proceed = input(\"Do you want to proceed with processing these files? (yes/no): \").strip().lower()\n",
    "    if proceed != \"yes\":\n",
    "        print(\"Processing aborted.\")\n",
    "        return\n",
    "\n",
    "    # Process training images\n",
    "    for img_path in train_image_paths:\n",
    "        process_one_image(img_path, is_train=True)\n",
    "\n",
    "    # Process testing images\n",
    "    for img_path in test_image_paths:\n",
    "        process_one_image(img_path, is_train=False)\n",
    "\n",
    "    print(\"Processing complete!\")\n",
    "    print(f\"Train images saved in: {OUT_IMG_TRAIN}, {OUT_MASK_TRAIN}\")\n",
    "    print(f\"Test images saved in: {OUT_IMG_TEST}, {OUT_MASK_TEST}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset_by_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "TRAIN_MASK_DIR = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "if not image_patches:\n",
    "    print(\"No train patches found.\")\n",
    "else:\n",
    "    rand_patch_name = random.choice(image_patches)  # e.g. 233582_im5_patch72.png\n",
    "    print(\"Random image patch:\", rand_patch_name)\n",
    "    \n",
    "    # Load image\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, rand_patch_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Construct mask filenames based on the correct naming convention\n",
    "    base_no_ext = os.path.splitext(rand_patch_name)[0]  # e.g. 233582_im5_patch72\n",
    "    base_parts = base_no_ext.rsplit(\"_\", 1)  # Split into [\"233582_im5\", \"patch72\"]\n",
    "    mask_base = base_parts[0]  # \"233582_im5\"\n",
    "    patch_index = base_parts[1]  # \"patch72\"\n",
    "    \n",
    "    # Construct mask filenames\n",
    "    root_mask_name  = f\"{mask_base}_root_mask_{patch_index}.tif\"\n",
    "    shoot_mask_name = f\"{mask_base}_shoot_mask_{patch_index}.tif\"\n",
    "    seed_mask_name  = f\"{mask_base}_seed_mask_{patch_index}.tif\"\n",
    "    \n",
    "    root_mask_path  = os.path.join(TRAIN_MASK_DIR, root_mask_name)\n",
    "    shoot_mask_path = os.path.join(TRAIN_MASK_DIR, shoot_mask_name)\n",
    "    seed_mask_path  = os.path.join(TRAIN_MASK_DIR, seed_mask_name)\n",
    "    \n",
    "    # Debugging paths\n",
    "    print(\"Looking for root mask at:\", root_mask_path)\n",
    "    print(\"Looking for shoot mask at:\", shoot_mask_path)\n",
    "    print(\"Looking for seed mask at:\", seed_mask_path)\n",
    "    \n",
    "    # Check if root mask exists and display\n",
    "    if os.path.exists(root_mask_path):\n",
    "        root_mask = tifffile.imread(root_mask_path)\n",
    "        overlay = img_rgb.copy()\n",
    "        overlay[root_mask > 0] = [255, 0, 0]  # Highlight root mask in red\n",
    "        blended = cv2.addWeighted(img_rgb, 0.6, overlay, 0.4, 0)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(img_rgb)\n",
    "        axs[0].set_title(\"Image Patch\")\n",
    "        axs[1].imshow(root_mask, cmap='gray')\n",
    "        axs[1].set_title(\"Root Mask\")\n",
    "        axs[2].imshow(blended)\n",
    "        axs[2].set_title(\"Overlay (root in red)\")\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No root mask found for this patch: {rand_patch_name}\")\n",
    "        # Print available mask files for debugging\n",
    "        print(\"Available mask files:\")\n",
    "        print(\"\\n\".join(os.listdir(TRAIN_MASK_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "TRAIN_MASK_DIR = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "if not image_patches:\n",
    "    print(\"No train patches found.\")\n",
    "else:\n",
    "    rand_patch_name = random.choice(image_patches)  # e.g. 233582_im5_patch72.png\n",
    "    print(\"Random image patch:\", rand_patch_name)\n",
    "    \n",
    "    # Load image\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, rand_patch_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Construct mask filenames based on the correct naming convention\n",
    "    base_no_ext = os.path.splitext(rand_patch_name)[0]  # e.g. 233582_im5_patch72\n",
    "    base_parts = base_no_ext.rsplit(\"_\", 1)  # Split into [\"233582_im5\", \"patch72\"]\n",
    "    \n",
    "    # Correctly construct mask filenames\n",
    "    root_mask_name  = f\"{base_parts[0]}_root_{base_parts[1]}.tif\"\n",
    "    shoot_mask_name = f\"{base_parts[0]}_shoot_{base_parts[1]}.tif\"\n",
    "    seed_mask_name  = f\"{base_parts[0]}_seed_{base_parts[1]}.tif\"\n",
    "    \n",
    "    root_mask_path  = os.path.join(TRAIN_MASK_DIR, root_mask_name)\n",
    "    shoot_mask_path = os.path.join(TRAIN_MASK_DIR, shoot_mask_name)\n",
    "    seed_mask_path  = os.path.join(TRAIN_MASK_DIR, seed_mask_name)\n",
    "    \n",
    "    # Debugging paths\n",
    "    print(\"Looking for root mask at:\", root_mask_path)\n",
    "    print(\"Looking for shoot mask at:\", shoot_mask_path)\n",
    "    print(\"Looking for seed mask at:\", seed_mask_path)\n",
    "    \n",
    "    # Check if root mask exists and display\n",
    "    if os.path.exists(root_mask_path):\n",
    "        root_mask = tifffile.imread(root_mask_path)\n",
    "        overlay = img_rgb.copy()\n",
    "        overlay[root_mask > 0] = [255, 0, 0]  # Highlight root mask in red\n",
    "        blended = cv2.addWeighted(img_rgb, 0.6, overlay, 0.4, 0)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(img_rgb)\n",
    "        axs[0].set_title(\"Image Patch\")\n",
    "        axs[1].imshow(root_mask, cmap='gray')\n",
    "        axs[1].set_title(\"Root Mask\")\n",
    "        axs[2].imshow(blended)\n",
    "        axs[2].set_title(\"Overlay (root in red)\")\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No root mask found for this patch: {rand_patch_name}\")\n",
    "        # Print available mask files for debugging\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directories for images and masks\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "TRAIN_MASK_DIR = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "missing_masks = []  # To collect details of missing masks\n",
    "\n",
    "# Iterate through image patches and check for corresponding masks\n",
    "for img_patch in image_patches:\n",
    "    base_no_ext = os.path.splitext(img_patch)[0]  # e.g., \"233582_im5_patch72\"\n",
    "    base_parts = base_no_ext.rsplit(\"_\", 1)       # Split into [\"233582_im5\", \"patch72\"]\n",
    "    \n",
    "    # Construct expected mask filenames\n",
    "    root_mask_name  = f\"{base_parts[0]}_root_{base_parts[1]}.tif\"\n",
    "    shoot_mask_name = f\"{base_parts[0]}_shoot_{base_parts[1]}.tif\"\n",
    "    seed_mask_name  = f\"{base_parts[0]}_seed_{base_parts[1]}.tif\"\n",
    "    \n",
    "    # Check existence of each mask\n",
    "    root_mask_path  = os.path.join(TRAIN_MASK_DIR, root_mask_name)\n",
    "    shoot_mask_path = os.path.join(TRAIN_MASK_DIR, shoot_mask_name)\n",
    "    seed_mask_path  = os.path.join(TRAIN_MASK_DIR, seed_mask_name)\n",
    "    \n",
    "    missing_for_patch = []\n",
    "    if not os.path.exists(root_mask_path):\n",
    "        missing_for_patch.append(\"root\")\n",
    "    if not os.path.exists(shoot_mask_path):\n",
    "        missing_for_patch.append(\"shoot\")\n",
    "    if not os.path.exists(seed_mask_path):\n",
    "        missing_for_patch.append(\"seed\")\n",
    "    \n",
    "    # Record missing masks for this patch\n",
    "    if missing_for_patch:\n",
    "        missing_masks.append({\n",
    "            \"image_patch\": img_patch,\n",
    "            \"missing_masks\": missing_for_patch\n",
    "        })\n",
    "\n",
    "# Output the results\n",
    "if not missing_masks:\n",
    "    print(\"All image patches have corresponding masks.\")\n",
    "else:\n",
    "    print(f\"Found {len(missing_masks)} image patches with missing masks:\")\n",
    "    for entry in missing_masks:\n",
    "        print(f\" - {entry['image_patch']} is missing: {', '.join(entry['missing_masks'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image patches: 1, Mask patches: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "train_img_dir = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "train_mask_dir = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "img_count = len(os.listdir(train_img_dir))\n",
    "mask_count = len(os.listdir(train_mask_dir))\n",
    "print(f\"Image patches: {img_count}, Mask patches: {mask_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m base_parts \u001b[38;5;241m=\u001b[39m base_no_ext\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)       \u001b[38;5;66;03m# Split into [\"233582_im5\", \"patch72\"]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Construct expected mask filenames\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m root_mask_name  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_parts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_root_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbase_parts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m shoot_mask_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_parts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shoot_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_parts[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m seed_mask_name  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_parts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_seed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_parts[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directories for images and masks\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "TRAIN_MASK_DIR = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "deleted_patches = []  # To keep track of deleted patches\n",
    "\n",
    "# Iterate through image patches and check for corresponding masks\n",
    "for img_patch in image_patches:\n",
    "    base_no_ext = os.path.splitext(img_patch)[0]  # e.g., \"233582_im5_patch72\"\n",
    "    base_parts = base_no_ext.rsplit(\"_\", 1)       # Split into [\"233582_im5\", \"patch72\"]\n",
    "    \n",
    "    # Construct expected mask filenames\n",
    "    root_mask_name  = f\"{base_parts[0]}_root_{base_parts[1]}.tif\"\n",
    "    shoot_mask_name = f\"{base_parts[0]}_shoot_{base_parts[1]}.tif\"\n",
    "    seed_mask_name  = f\"{base_parts[0]}_seed_{base_parts[1]}.tif\"\n",
    "    \n",
    "    root_mask_path  = os.path.join(TRAIN_MASK_DIR, root_mask_name)\n",
    "    shoot_mask_path = os.path.join(TRAIN_MASK_DIR, shoot_mask_name)\n",
    "    seed_mask_path  = os.path.join(TRAIN_MASK_DIR, seed_mask_name)\n",
    "    \n",
    "    # Check for missing masks\n",
    "    missing = not os.path.exists(root_mask_path) or not os.path.exists(shoot_mask_path) or not os.path.exists(seed_mask_path)\n",
    "    \n",
    "    if missing:\n",
    "        # Delete the image patch\n",
    "        img_path = os.path.join(TRAIN_IMG_DIR, img_patch)\n",
    "        os.remove(img_path)\n",
    "        \n",
    "        # Delete the associated masks if they exist\n",
    "        if os.path.exists(root_mask_path):\n",
    "            os.remove(root_mask_path)\n",
    "        if os.path.exists(shoot_mask_path):\n",
    "            os.remove(shoot_mask_path)\n",
    "        if os.path.exists(seed_mask_path):\n",
    "            os.remove(seed_mask_path)\n",
    "        \n",
    "        # Track the deleted patch\n",
    "        deleted_patches.append(img_patch)\n",
    "\n",
    "# Output the results\n",
    "if not deleted_patches:\n",
    "    print(\"No patches with missing masks were found.\")\n",
    "else:\n",
    "    print(f\"Deleted {len(deleted_patches)} patches with missing masks:\")\n",
    "    for patch in deleted_patches:\n",
    "        print(f\" - {patch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random image patch: .DS_Store\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_IMG_DIR, rand_patch_name)\n\u001b[1;32m     20\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m---> 21\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Construct mask filenames based on the correct naming convention\u001b[39;00m\n\u001b[1;32m     24\u001b[0m base_no_ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(rand_patch_name)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# e.g. 233582_im5_patch72\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "TRAIN_MASK_DIR = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "if not image_patches:\n",
    "    print(\"No train patches found.\")\n",
    "else:\n",
    "    rand_patch_name = random.choice(image_patches)  # e.g. 233582_im5_patch72.png\n",
    "    print(\"Random image patch:\", rand_patch_name)\n",
    "    \n",
    "    # Load image\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, rand_patch_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Construct mask filenames based on the correct naming convention\n",
    "    base_no_ext = os.path.splitext(rand_patch_name)[0]  # e.g. 233582_im5_patch72\n",
    "    base_parts = base_no_ext.rsplit(\"_\", 1)  # Split into [\"233582_im5\", \"patch72\"]\n",
    "    \n",
    "    # Correctly construct mask filenames\n",
    "    root_mask_name  = f\"{base_parts[0]}_root_{base_parts[1]}.tif\"\n",
    "    shoot_mask_name = f\"{base_parts[0]}_shoot_{base_parts[1]}.tif\"\n",
    "    seed_mask_name  = f\"{base_parts[0]}_seed_{base_parts[1]}.tif\"\n",
    "    \n",
    "    root_mask_path  = os.path.join(TRAIN_MASK_DIR, root_mask_name)\n",
    "    shoot_mask_path = os.path.join(TRAIN_MASK_DIR, shoot_mask_name)\n",
    "    seed_mask_path  = os.path.join(TRAIN_MASK_DIR, seed_mask_name)\n",
    "    \n",
    "    # Debugging paths\n",
    "    print(\"Looking for root mask at:\", root_mask_path)\n",
    "    print(\"Looking for shoot mask at:\", shoot_mask_path)\n",
    "    print(\"Looking for seed mask at:\", seed_mask_path)\n",
    "    \n",
    "    # Check if root mask exists and display\n",
    "    if os.path.exists(root_mask_path):\n",
    "        root_mask = tifffile.imread(root_mask_path)\n",
    "        overlay = img_rgb.copy()\n",
    "        overlay[root_mask > 0] = [255, 0, 0]  # Highlight root mask in red\n",
    "        blended = cv2.addWeighted(img_rgb, 0.6, overlay, 0.4, 0)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(img_rgb)\n",
    "        axs[0].set_title(\"Image Patch\")\n",
    "        axs[1].imshow(root_mask, cmap='gray')\n",
    "        axs[1].set_title(\"Root Mask\")\n",
    "        axs[2].imshow(blended)\n",
    "        axs[2].set_title(\"Overlay (root in red)\")\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No root mask found for this patch: {rand_patch_name}\")\n",
    "        # Print available mask files for debugging\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory for train image patches\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "\n",
    "# Threshold for nearly black pixels\n",
    "BLACK_THRESHOLD = 10  # Pixels with intensity < 10 are considered nearly black\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "black_patches = []\n",
    "\n",
    "# Check for nearly black patches\n",
    "for img_patch in image_patches:\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, img_patch)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to read: {img_patch}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the patch is nearly black\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if np.max(gray_img) < BLACK_THRESHOLD:\n",
    "        black_patches.append(img_patch)\n",
    "\n",
    "# Display results\n",
    "if not black_patches:\n",
    "    print(\"No nearly black patches found.\")\n",
    "else:\n",
    "    print(f\"Found {len(black_patches)} nearly black patches.\")\n",
    "    \n",
    "    # Create a grid to display all nearly black patches\n",
    "    cols = 5  # Number of columns for the grid\n",
    "    rows = (len(black_patches) + cols - 1) // cols  # Calculate number of rows\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, rows * 3))\n",
    "\n",
    "    # Flatten axes for consistent handling\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Display all nearly black patches\n",
    "    for i, patch in enumerate(black_patches):\n",
    "        img_path = os.path.join(TRAIN_IMG_DIR, patch)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(img_rgb)\n",
    "        axs[i].set_title(patch, fontsize=8)\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    # Hide unused axes\n",
    "    for j in range(len(black_patches), len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Directory for train image patches\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "TRAIN_MASK_DIR = \"/Users/celinewu/Documents/dataset_patches/masks/train\"\n",
    "\n",
    "# Threshold for nearly black pixels\n",
    "BLACK_THRESHOLD = 10  # Pixels with intensity < 10 are considered nearly black\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "black_patches = []\n",
    "\n",
    "# Check for nearly black patches\n",
    "for img_patch in image_patches:\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, img_patch)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to read: {img_patch}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the patch is nearly black\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if np.max(gray_img) < BLACK_THRESHOLD:\n",
    "        black_patches.append(img_patch)\n",
    "\n",
    "# Delete the nearly black patches and their corresponding masks\n",
    "if not black_patches:\n",
    "    print(\"No nearly black patches found.\")\n",
    "else:\n",
    "    print(f\"Found {len(black_patches)} nearly black patches.\")\n",
    "    \n",
    "    for patch in black_patches:\n",
    "        # Delete the image patch\n",
    "        img_path = os.path.join(TRAIN_IMG_DIR, patch)\n",
    "        os.remove(img_path)\n",
    "        print(f\"Deleted image patch: {patch}\")\n",
    "        \n",
    "        # Construct corresponding mask filenames based on naming convention\n",
    "        base_no_ext = os.path.splitext(patch)[0]  # e.g., \"233582_im5_patch72\"\n",
    "        base_parts = base_no_ext.rsplit(\"_\", 1)   # Split into [\"233582_im5\", \"patch72\"]\n",
    "        \n",
    "        root_mask_name  = f\"{base_parts[0]}_root_{base_parts[1]}.tif\"\n",
    "        shoot_mask_name = f\"{base_parts[0]}_shoot_{base_parts[1]}.tif\"\n",
    "        seed_mask_name  = f\"{base_parts[0]}_seed_{base_parts[1]}.tif\"\n",
    "        \n",
    "        root_mask_path  = os.path.join(TRAIN_MASK_DIR, root_mask_name)\n",
    "        shoot_mask_path = os.path.join(TRAIN_MASK_DIR, shoot_mask_name)\n",
    "        seed_mask_path  = os.path.join(TRAIN_MASK_DIR, seed_mask_name)\n",
    "        \n",
    "        # Delete corresponding masks if they exist\n",
    "        if os.path.exists(root_mask_path):\n",
    "            os.remove(root_mask_path)\n",
    "            print(f\"Deleted root mask: {root_mask_name}\")\n",
    "        if os.path.exists(shoot_mask_path):\n",
    "            os.remove(shoot_mask_path)\n",
    "            print(f\"Deleted shoot mask: {shoot_mask_name}\")\n",
    "        if os.path.exists(seed_mask_path):\n",
    "            os.remove(seed_mask_path)\n",
    "            print(f\"Deleted seed mask: {seed_mask_name}\")\n",
    "\n",
    "    print(\"Deletion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No nearly black patches found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory for train image patches\n",
    "TRAIN_IMG_DIR = \"/Users/celinewu/Documents/dataset_patches/images/train\"\n",
    "\n",
    "# Threshold for nearly black pixels\n",
    "BLACK_THRESHOLD = 10  # Pixels with intensity < 10 are considered nearly black\n",
    "\n",
    "# List all image patches\n",
    "image_patches = os.listdir(TRAIN_IMG_DIR)\n",
    "black_patches = []\n",
    "\n",
    "# Check for nearly black patches\n",
    "for img_patch in image_patches:\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, img_patch)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to read: {img_patch}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the patch is nearly black\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if np.max(gray_img) < BLACK_THRESHOLD:\n",
    "        black_patches.append(img_patch)\n",
    "\n",
    "# Display results\n",
    "if not black_patches:\n",
    "    print(\"No nearly black patches found.\")\n",
    "else:\n",
    "    print(f\"Found {len(black_patches)} nearly black patches.\")\n",
    "    \n",
    "    # Create a grid to display all nearly black patches\n",
    "    cols = 5  # Number of columns for the grid\n",
    "    rows = (len(black_patches) + cols - 1) // cols  # Calculate number of rows\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, rows * 3))\n",
    "\n",
    "    # Flatten axes for consistent handling\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Display all nearly black patches\n",
    "    for i, patch in enumerate(black_patches):\n",
    "        img_path = os.path.join(TRAIN_IMG_DIR, patch)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(img_rgb)\n",
    "        axs[i].set_title(patch, fontsize=8)\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    # Hide unused axes\n",
    "    for j in range(len(black_patches), len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
