{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab task 4\n",
    "\n",
    "### moving the masks from one folder to \"train_masks\" and \"val_masks\" based on the images folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_folder = r\"/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/dataset\"\n",
    "folders_to_check = [\"train_images\", \"val_images\"]\n",
    "\n",
    "# Print all files in train_images and val_images\n",
    "for folder in folders_to_check:\n",
    "    folder_path = os.path.join(base_folder, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"Files in {folder_path}:\")\n",
    "        print(os.listdir(folder_path))\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    " \n",
    "# List of filenames to delete (include extensions)\n",
    "files_to_delete = [\n",
    "    \"000_43-2-ROOT1-2023-08-08_pvd_OD0001_f6h1_02-Fish Eye Corrected.png\",\n",
    "    \"000_43-18-ROOT1-2023-08-08_pvdCherry_OD001_Col0_01-Fish Eye Corrected.png\",\n",
    "    \"008_43-2-ROOT1-2023-08-08_control_pH7_-Fe+B_col0_03-Fish Eye Corrected.png\",\n",
    "    \"008_43-17-ROOT1-2023-08-08_pvdCherry_OD001_Col0_01-Fish Eye Corrected.png\",\n",
    "    \"019_43-6-ROOT1-2023-08-08_control_pH7_-Fe+B_col0_01-Fish Eye Corrected.png\",\n",
    "    \"019_43-19-ROOT1-2023-08-08_pvd_OD001_Col0_03-Fish Eye Corrected.png\",\n",
    "    \"023_43-14-ROOT1-2023-08-08_pvdCherry_OD0001_f6h1_03-Fish Eye Corrected.png\",\n",
    "    \"023_43-18-ROOT1-2023-08-08_pvd_OD001_f6h1_01-Fish Eye Corrected.png\",\n",
    "]\n",
    " \n",
    "# Iterate through the specified folders\n",
    "for folder in folders_to_check:\n",
    "    folder_path = os.path.join(base_folder, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        for file_name in files_to_delete:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            else:\n",
    "                print(f\"File not found (skipping): {file_path}\")\n",
    "    else:\n",
    "        print(f\"Folder not found (skipping): {folder_path}\")\n",
    " \n",
    "print(\"Deletion process complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the directories\n",
    "root_dir = '/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4'  # Replace with the absolute path to the root folder\n",
    "dataset_dir = os.path.join(root_dir, 'dataset')\n",
    "masks_dir = os.path.join(root_dir, 'masks')\n",
    "\n",
    "train_images_dir = os.path.join(dataset_dir, 'train_images')\n",
    "train_masks_dir = os.path.join(dataset_dir, 'train_masks')\n",
    "\n",
    "val_images_dir = os.path.join(dataset_dir, 'val_images')\n",
    "val_masks_dir = os.path.join(dataset_dir, 'val_masks')\n",
    "\n",
    "# Create the train_masks and val_masks directories if they don't exist\n",
    "os.makedirs(train_masks_dir, exist_ok=True)\n",
    "os.makedirs(val_masks_dir, exist_ok=True)\n",
    "\n",
    "# Helper function to extract everything before \"Corrected\" in the filename\n",
    "def extract_before_corrected(filename):\n",
    "    \"\"\"Extracts everything before the word 'Corrected'.\"\"\"\n",
    "    if 'Corrected' in filename:\n",
    "        part_before_corrected = filename.split('Corrected', 1)[0]\n",
    "        return part_before_corrected.rstrip('-_')  # Remove any trailing dashes or underscores\n",
    "    return None\n",
    "\n",
    "# Get list of blocks from train and val images\n",
    "train_image_blocks = {extract_before_corrected(filename) for filename in os.listdir(train_images_dir) if filename.endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))}\n",
    "val_image_blocks = {extract_before_corrected(filename) for filename in os.listdir(val_images_dir) if filename.endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))}\n",
    "\n",
    "# Get list of mask filenames from the masks folder (only .tif and .tiff files)\n",
    "mask_filenames = {filename for filename in os.listdir(masks_dir) if filename.endswith(('.tif', '.tiff'))}\n",
    "\n",
    "# Print debug info to see what's being matched\n",
    "print(f\"Train image blocks: {train_image_blocks}\")\n",
    "print(f\"Val image blocks: {val_image_blocks}\")\n",
    "print(f\"Total masks found: {len(mask_filenames)}\")\n",
    "\n",
    "# Copy corresponding masks to train_masks and val_masks\n",
    "for mask_filename in mask_filenames:\n",
    "    mask_block = extract_before_corrected(mask_filename)  # Extract the block before \"Corrected\" from the mask filename\n",
    "    source_path = os.path.join(masks_dir, mask_filename)\n",
    "    \n",
    "    if mask_block in train_image_blocks:\n",
    "        dest_path = os.path.join(train_masks_dir, mask_filename)\n",
    "        shutil.move(source_path, dest_path)\n",
    "        print(f'Copied {mask_filename} to train_masks/')\n",
    "    \n",
    "    elif mask_block in val_image_blocks:\n",
    "        dest_path = os.path.join(val_masks_dir, mask_filename)\n",
    "        shutil.move(source_path, dest_path)\n",
    "        print(f'Copied {mask_filename} to val_masks/')\n",
    "    else:\n",
    "        print(f'No match for mask {mask_filename} (block: {mask_block})')\n",
    "\n",
    "print('Done copying masks to train_masks and val_masks.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    gray = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                 cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    return gray, image\n",
    "\n",
    "def detect_edges(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150) \n",
    "    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))  \n",
    "    return edges\n",
    "\n",
    "def find_largest_bounding_box(edges, image_shape, min_size_ratio=0.3):\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area = 0\n",
    "    best_bbox = None\n",
    "    min_width, min_height = min_size_ratio * image_shape[1], min_size_ratio * image_shape[0]\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = w * h\n",
    "        if area > max_area and w >= min_width and h >= min_height:\n",
    "            max_area = area\n",
    "            best_bbox = (x, y, w, h)\n",
    "    \n",
    "    return best_bbox\n",
    "\n",
    "def crop_to_square(image, bbox, padding=5):\n",
    "    x, y, w, h = bbox\n",
    "    size = max(w, h)  \n",
    "    \n",
    "    # Center crop around the bounding box\n",
    "    cx, cy = x + w // 2, y + h // 2\n",
    "    x1 = max(0, cx - size // 2)\n",
    "    y1 = max(0, cy - size // 2)\n",
    "    x2 = min(image.shape[1], x1 + size)\n",
    "    y2 = min(image.shape[0], y1 + size)\n",
    "\n",
    "    # Crop the image\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def crop_and_replace_images_in_folder(input_folder, min_size_ratio=0.2, padding=30):\n",
    "    # List all image files in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Check if the file is an image (you can add more extensions if needed)\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff')):\n",
    "            # Read the image\n",
    "            image = cv2.imread(file_path)\n",
    "            \n",
    "            # Preprocess the image\n",
    "            gray, original = preprocess_image(image)\n",
    "            edges = detect_edges(gray)\n",
    "            \n",
    "            # Find the bounding box\n",
    "            bbox = find_largest_bounding_box(edges, gray.shape, min_size_ratio=min_size_ratio)  \n",
    "            \n",
    "            if bbox:\n",
    "                # Crop the image to a square around the bounding box\n",
    "                cropped = crop_to_square(original, bbox, padding=padding)\n",
    "                \n",
    "                # Replace the original image with the cropped image\n",
    "                cv2.imwrite(file_path, cropped)  # Save the cropped image to the same path\n",
    "                print(f\"Cropped and replaced {filename}.\")\n",
    "            else:\n",
    "                print(f\"No bounding box detected for {filename}\")\n",
    "        else:\n",
    "            print(f\"{filename} is not an image file.\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = '/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/dataset/val_images'  \n",
    "\n",
    "# Call the function to crop and replace all images in the folder\n",
    "crop_and_replace_images_in_folder(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/dataset/train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = cv2.imread(\"/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/dataset/val_masks/030_43-2-ROOT1-2023-08-08_pvdCherry_OD001_Col0_05-Fish Eye Corrected_seed_mask.tif\")\n",
    "height, width, channels = im_path.shape\n",
    "print(width, height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = cv2.imread(\"dataset/val_masks/031_43-18-ROOT1-2023-08-08_pvd_OD0001_col-0_05-Fish Eye Corrected_root_mask.tif\")\n",
    "height, width, channels = im_path.shape\n",
    "print(width, height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Image data type: {im_path.dtype}')\n",
    "print(f'Mask data type: {mask_path.dtype}')\n",
    "print(f'Image pixel values: {np.min(im_path)}-{np.max(im_path)}')\n",
    "print(f'Mask pixel values: {np.min(mask_path)}-{np.max(mask_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, patch_size=256):\n",
    "    \"\"\"\n",
    "    Pads the image to make its dimensions a multiple of patch_size.\n",
    "    \"\"\"\n",
    "    height, width, channels = image.shape if len(image.shape) == 3 else (*image.shape, 1)\n",
    "    \n",
    "    new_height = ((height // patch_size) + 1) * patch_size if height % patch_size != 0 else height\n",
    "    new_width = ((width // patch_size) + 1) * patch_size if width % patch_size != 0 else width\n",
    "    \n",
    "    pad_height = new_height - height\n",
    "    pad_width = new_width - width\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    padded_image = cv2.copyMakeBorder(image, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    \n",
    "    return padded_image\n",
    "\n",
    "def extract_patches(image, patch_size=256):\n",
    "    \"\"\"\n",
    "    Extracts non-overlapping patches of size patch_size x patch_size from the image.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    height, width, channels = image.shape if len(image.shape) == 3 else (*image.shape, 1)\n",
    "    \n",
    "    for y in range(0, height, patch_size):\n",
    "        for x in range(0, width, patch_size):\n",
    "            patch = image[y:y + patch_size, x:x + patch_size]\n",
    "            if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
    "                patches.append(patch)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def save_patches(patches, output_folder, image_index):\n",
    "    \"\"\"\n",
    "    Saves each patch as an image file in the specified output folder with the new naming convention.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    for i, patch in enumerate(patches):\n",
    "        patch_filename = os.path.join(output_folder, f\"image{image_index}_patch{i+1:04d}.png\")\n",
    "        cv2.imwrite(patch_filename, patch)\n",
    "\n",
    "def process_folder(image_folder, output_folder, patch_size=256):\n",
    "    \"\"\"\n",
    "    Processes all images in the folder, renames them sequentially (image1, image2, etc.),\n",
    "    extracts patches, and saves the patches in the new directory with new names.\n",
    "    \"\"\"\n",
    "    image_index = 1  \n",
    "    \n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')): \n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "            print(f\"Processing image: {filename}\")\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            padded_image = pad_image(image, patch_size=patch_size)\n",
    "            \n",
    "            print(f\"Padded image size for {filename}: {padded_image.shape}\")\n",
    "            \n",
    "            image_patches = extract_patches(padded_image, patch_size=patch_size)\n",
    "            \n",
    "            save_patches(image_patches, output_folder, image_index)\n",
    "            \n",
    "            print(f\"Saved patches for {filename} in {output_folder}\")\n",
    "            \n",
    "            image_index += 1  \n",
    "    \n",
    "    print(\"All images processed successfully!\")\n",
    "\n",
    "# Define paths for images\n",
    "base_path = '/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/dataset'  # Update with the path to your image folder\n",
    "new_base_path = '/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/ds'  # Update with the desired output folder\n",
    "\n",
    "# Image paths\n",
    "image_folder = os.path.join(base_path, 'val_images')  \n",
    "output_folder = os.path.join(new_base_path, 'val_images1')  \n",
    "\n",
    "# Patch size\n",
    "patch_size = 256\n",
    "\n",
    "# Process the image folder\n",
    "process_folder(image_folder, output_folder, patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, patch_size=256):\n",
    "    height, width, channels = image.shape if len(image.shape) == 3 else (*image.shape, 1)\n",
    "    \n",
    "    # Proper rounding to the next multiple of patch_size\n",
    "    new_height = ((height + patch_size - 1) // patch_size) * patch_size\n",
    "    new_width = ((width + patch_size - 1) // patch_size) * patch_size\n",
    "    \n",
    "    pad_height = new_height - height\n",
    "    pad_width = new_width - width\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    padded_image = cv2.copyMakeBorder(image, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "def extract_patches(image, patch_size=256):\n",
    "    patches = []\n",
    "    height, width, channels = image.shape if len(image.shape) == 3 else (*image.shape, 1)\n",
    "    \n",
    "    # Loop to avoid overshooting\n",
    "    for y in range(0, height - patch_size + 1, patch_size):\n",
    "        for x in range(0, width - patch_size + 1, patch_size):\n",
    "            patch = image[y:y + patch_size, x:x + patch_size]\n",
    "            if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
    "                patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def save_patches(patches, output_folder, image_index):\n",
    "    \"\"\"\n",
    "    Saves each patch as an image file in the specified output folder with the new naming convention.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    for i, patch in enumerate(patches):\n",
    "        patch_filename = os.path.join(output_folder, f\"image{image_index}_patch{i+1:04d}.png\")\n",
    "        cv2.imwrite(patch_filename, patch)\n",
    "\n",
    "def process_folder(image_folder, output_folder, patch_size=256):\n",
    "    \"\"\"\n",
    "    Processes all images in the folder, renames them sequentially (image1, image2, etc.),\n",
    "    extracts patches, and saves the patches in the new directory with new names.\n",
    "    \"\"\"\n",
    "    image_index = 1  \n",
    "    \n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith('Corrected_root_mask.tif'): \n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "            print(f\"Processing image: {filename}\")\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            padded_image = pad_image(image, patch_size=patch_size)\n",
    "            \n",
    "            print(f\"Padded image size for {filename}: {padded_image.shape}\")\n",
    "            \n",
    "            image_patches = extract_patches(padded_image, patch_size=patch_size)\n",
    "            \n",
    "            # Save the patches with the new naming convention\n",
    "            save_patches(image_patches, output_folder, image_index)\n",
    "            \n",
    "            print(f\"Saved patches for {filename} in {output_folder}\")\n",
    "            \n",
    "            image_index += 1  \n",
    "    \n",
    "    print(\"All images processed successfully!\")\n",
    "\n",
    "# Define paths for images\n",
    "base_path = '/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/dataset'  \n",
    "new_base_path = '/Users/celinewu/Documents/GitHub/2024-25b-fai2-adsai-CelineWu231265/datalab_tasks/task_4/ds'  \n",
    "\n",
    "# Image paths\n",
    "image_folder = os.path.join(base_path, 'val_masks')  \n",
    "output_folder = os.path.join(new_base_path, 'val_masks1')  \n",
    "\n",
    "# Patch size\n",
    "patch_size = 256\n",
    "\n",
    "# Process the image folder\n",
    "process_folder(image_folder, output_folder, patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop \n",
    "get size \n",
    "combine the masks \n",
    "apply size to padding \n",
    "patch using padding size 256\n",
    "save the patches into x and y should be 9 patches per image \n",
    "check images and masks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
