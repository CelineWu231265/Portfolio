{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Extract and translate sentences from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import assemblyai as aai\n",
    "import os\n",
    "from pytubefix import YouTube\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'  # Suppress Python warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=dN3mv5QiZLY&t=952s\"\n",
    "output_path = \"extracted_sentences.csv\"\n",
    "aai.settings.api_key = '4ba97f247dd44f86b2c51a29f14caa26'\n",
    "model_path = \"./translation_model\"  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aai.settings.api_key = ASSEMBLYAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def video_transcription(video_url, output_path):\n",
    "    \n",
    "    # url input from youtube\n",
    "    yt = YouTube(video_url)\n",
    "\n",
    "    # extract only audio\n",
    "    video = yt.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # set destination to save file\n",
    "    #destination = (\"/Users/Buas/Desktop/Data Start/GitHub/Ano 2/2024-25c-fai2-adsai-DeuzaVarela235065/Data\")\n",
    "\n",
    "    # download the file\n",
    "    out_file = video.download()\n",
    "\n",
    "    # save the file\n",
    "    base, ext = os.path.splitext(out_file)\n",
    "    new_file = base + '.mp3'\n",
    "    os.rename(out_file, new_file)\n",
    "    \n",
    "    # Configure transcription with Spanish language\n",
    "    config = aai.TranscriptionConfig(language_code=\"es\")\n",
    "    transcriber = aai.Transcriber(config=config)\n",
    "\n",
    "    # Transcribe the audio\n",
    "    transcript = transcriber.transcribe(new_file)\n",
    "\n",
    "    # Check for errors\n",
    "    if transcript.status == aai.TranscriptStatus.error:\n",
    "        print(f\"Transcription failed: {transcript.error}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Create lists to store data\n",
    "    sentences = []\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "\n",
    "    # Extract sentences with their timestamps\n",
    "    sentence_objects = transcript.get_sentences()\n",
    "    for sentence in sentence_objects:\n",
    "        sentences.append(sentence.text)\n",
    "        start_times.append(sentence.start)  # Start time in milliseconds\n",
    "        end_times.append(sentence.end)      # End time in milliseconds\n",
    "\n",
    "    # Convert to DataFrame for easier manipulation\n",
    "    transcript_df = pd.DataFrame({\n",
    "        'sentence': sentences,\n",
    "        'start_time_ms': start_times,\n",
    "        'end_time_ms': end_times\n",
    "    })\n",
    "\n",
    "    # Convert milliseconds to a more readable format\n",
    "    transcript_df['start_time'] = transcript_df['start_time_ms'].apply(\n",
    "        lambda ms: f\"{int(ms/60000):02d}:{int((ms%60000)/1000):02d}.{int(ms%1000):03d}\"\n",
    "    )\n",
    "    transcript_df['end_time'] = transcript_df['end_time_ms'].apply(\n",
    "        lambda ms: f\"{int(ms/60000):02d}:{int((ms%60000)/1000):02d}.{int(ms%1000):03d}\"\n",
    "    )\n",
    "\n",
    "    # Format the DataFrame\n",
    "    transcript_df = transcript_df[['start_time', 'end_time', 'sentence']]\n",
    "\n",
    "    # Rename the columns as per template\n",
    "    transcript_df.columns = ['Start Time', 'End Time', 'Sentence']\n",
    "    \n",
    "\n",
    "    # Save to CSV for the next step in your pipeline\n",
    "    transcript_df.to_csv(output_path, index=False)\n",
    "\n",
    "    #print(f\"Extracted {len(sentences)} sentences with timestamps and saved to {output_path}\")\n",
    "    return transcript_df\n",
    "\n",
    "video_df = video_transcription(video_url, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Translate the sentences to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Translate a column of sentences ===\n",
    "def translate(sentence):\n",
    "       \n",
    "    # Tokenize input sentence\n",
    "    inputs = tokenizer.encode(sentence, return_tensors=\"tf\", padding=True, truncation=True, max_length=256)\n",
    "    # Generate translation\n",
    "    outputs = model.generate(inputs, max_length=256)\n",
    "    # Decode the output\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Apply translation to the column (replace 'sentence' with your actual column name)\n",
    "video_df['Translation'] = video_df['Sentence'].apply(translate)\n",
    "\n",
    "# Save the DataFrame with translations to a new CSV file\n",
    "video_df.to_csv(\"translated_output.csv\", index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
