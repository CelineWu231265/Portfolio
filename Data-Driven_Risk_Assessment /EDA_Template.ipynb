{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python notebook template block B\n",
    "\n",
    "As of now, you created a new notebook for every study day with the related contents. However, when working on a project in the real life, all your data and code needs to be in one place for the project. Going forward in the block, all of the code that you generate with regard to the final project about NAC and the ILO's should be in this one template. Go back to the code you wrote for the previous weeks, evaluate if it is according to [PEP8](https://peps.python.org/pep-0008/) style guide and adjust where necessary. This template provides you with a natural flow through the steps of a traditional data science project. Do not forget to clearly add comments to your code. If you would like to add more stucture, add extra mark down blocks to explain what you are doing. You are **not** allowed to remove code blocks! All blocks in here need to be filled with code. If you did not write code for a section, leave the code block as is with the pre-filled in comment. Adjust this template to your needs, make sure that all your evidence for all of the ILO's is included.\n",
    "\n",
    "⚠️Important! Before handing it in, run all of your code. All your cells need to show outputs. This is necessary for grading!⚠️\n",
    "\n",
    "The ILO's for which you can evidence your code by this notebook are: \n",
    "\n",
    "| ILO | Poor | Insufficient | Sufficient | Good | Excellent |\n",
    "|-----|------|--------------|------------|------|-----------|\n",
    "| 4.1 | x    | x            | x          | x    | x         |\n",
    "| 4.2 | x    | x            | x          | x    | x*        |\n",
    "| 5.0 | x    | x            | x          | x    | x         |\n",
    "| 7.0 | x    | x            | x          | x    | x         |\n",
    "\n",
    "4.2 excellent*: If you would like to showcast your graphs using streamlit, you need to hand in a seperate .py file. Evidence accordingly in your learning log.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add imports here\n",
    "When working in .py files, you usually have all your package imports at the top of your code. This makes it easy to get a good overview of the packages that you are using and importing. As of now, we are working in .ipynb, but it is good practice to already start implementing these structures. Add all the imports that you use in all of your code in the code block below. In this way, you do not need to add it in every cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your package imports here\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import missingno as msno \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "After your package imports, you usually load your data. This is what you will be working with and what your code will be based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fresh dataframe\n",
    "df= pd.read_csv(\"N1.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing\n",
    "In the following section plug in all of your relevant python codes and explanations related to data cleansing. This is related to the poor and insufficient criteria of ILO 4.1 and 4.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### explanations\n",
    "I started off my data preprocessing with some personal preferences, I used 'display.max_rows' to display all the wors in the output. \n",
    "I used replace() to replace the space between words with '_' in the column names to make it easier to read. \n",
    "\n",
    "Pre-Processing the dataset, my first step was to see which columns has missing data. Using msno.bar() I visualized my dataset, but that was not the most ideal way to find missing data by using isnull().sum() I could go through every column and see exactly how many values are missing in each of them. \n",
    "\n",
    "Contract Expiration had a significant amount of missing data, there are many different ways that I can use to replace these missing values but I chose to use the median of \"Contract expires\". I visualized the \"Contract expires\" data and saw that there were a couple of outliers, which is why I chose to use the median as it is less sensitive to outliers compared to mean. Out of pure curiosity I checked what the mode of (\"Contract expires) was and it was the same as the median, namely, \"2024-06-30\". As the values were strings, I had to convert the datatype to datetime to be able to calculate the median and i did that by using 'to_datetime()'.\n",
    "\n",
    "Then I had the columns such as \"shots against per 90\", most of these columns had missing data, this is because these depend on the player's position. I named these type of columns positional columns. A goalkeeper for example, would generally not have data for the column such as \"Received passes per 90\". The empty values in these columns, I replaced with 0. \n",
    "\n",
    "The column \"Foot\" had me a bit stumped, I was not sure as to what I should do with the missing values. Ultimately I decided that it wasn't an important variable in my dataset so I replaced it with the mode, which was \"Right\". \n",
    "\n",
    "Afterwards I called 'missing_values_count' again and there were many columns with a small amount of missing data so I decided to move on to the rows. I deleted rows that had a lot of missing values. I used a threshold of 115, meaning that I kept all the rows with at least 115 of non-NaN values. I didn't know what my threshold should be so I kept playing with different numbers until the sum of every column with missing data was 0, which is when the threshold is 115\n",
    "\n",
    "Save the new dataset \n",
    "\n",
    "Call the new dataset\n",
    "\n",
    "I had to call the new dataset because I want to add a new column to the new dataset. \n",
    "I added a new column named \"Risk_assessment\". I binned the players into 3 different categories based on different conditions. My three categories are 'High risk', 'Risky' and  'Low risk'. I based my conditions off of the information I found in an article called \"Player’s Guide to Red Cards, Yellow Cards and Accumulated Disciplinary Points\" from the National Capital Soccer League. From reading that I found out that 2 red cards equals to 20 Disciplinary Points (which I will call DP from now on) and the player has to sit out the next game. 4 yellow cards also equals to 20 DP's and the player has to sit out the next game, so what I got from that is 2 yellow cards equals to 1 red card. \n",
    "\n",
    "My conditions for 'High risk' are: if a a player has more or equal to 2 red cards and more or equal to 4 yellow cards, if a player has 1 red card and more or equal to 6 yellow cards, and lastly 0 red cards and more than 8 yellow cards. I classified these as high risk because 2 red cards or 4 yellow cards equals 20 DP's, 2 red and 4 yellow cards in my mind means 4 red cards. The other 2 conditions I used to define 'High risk' add up to being 4 red cards. My conditions for 'Risky' is as follows: if a player has 2 red cards and less than 4 yellow cards, if a player has 1 red card and less than 6 yellow cards, and lastly 0 red cards and between 4 and 8 yellow cards. If you convert all the yellow cards to red cards like I did before they all come out to less than 4 red cards, which is why I determined for these conditions to be risky. Lastly, for 'Low risk' my only condition was 0 red cards and less than 4 yellow cards.\n",
    "\n",
    "I saved the new fully pre-processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Contract_expires'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/block_b/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/block_b/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/block_b/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Contract_expires'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m missing_values_count\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the 'Contract_expires' column to datetime format\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContract_expires\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContract_expires\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate and display the median date\u001b[39;00m\n\u001b[1;32m     15\u001b[0m median_date \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContract_expires\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\n",
      "File \u001b[0;32m~/anaconda3/envs/block_b/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/block_b/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Contract_expires'"
     ]
    }
   ],
   "source": [
    "# Display max rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Replace the space with underscore \n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "\n",
    "# Count missing values \n",
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count\n",
    "\n",
    "# Convert the 'Contract_expires' column to datetime format\n",
    "df['Contract_expires'] = pd.to_datetime(df['Contract_expires'], errors='coerce')\n",
    "\n",
    "# Calculate and display the median date\n",
    "median_date = df['Contract_expires'].median()\n",
    "median_date\n",
    "\n",
    "# Replace missing values in 'Contract_expires' with the median date\n",
    "df['Contract_expires'].fillna(median_date, inplace=True)\n",
    "\n",
    "# Replacing missing values in positional columns with 0\n",
    "positional_columns = ['Direct_free_kicks_on_target,_%', 'Direct_free_kicks_per_90', \n",
    "                      'Free_kicks_per_90', 'Aerial_duels_per_90.1', 'Exits_per_90', \n",
    "                      'Prevented_goals_per_90', 'Prevented_goals', \n",
    "                      'Shots_against_per_90', 'Conceded_goals_per_90']\n",
    "df[positional_columns] = df[positional_columns].fillna(0)\n",
    "\n",
    "# Replace missing values in 'Foot' with the mode\n",
    "df['Foot'].fillna(df['Foot'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop the rows with a lot of missing data \n",
    "threshold = 115\n",
    "df.dropna(thresh= threshold, inplace= True)\n",
    "\n",
    "# Count missing values \n",
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count\n",
    "\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('NAC1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the new dataframe\n",
    "# Pre-processed dataframe\n",
    "df2 = pd.read_csv(\"NAC1.csv\")\n",
    "\n",
    "# Define the conditions\n",
    "conditions = [\n",
    "    (df2['Red_cards'] >= 2) & (df2['Yellow_cards'] >= 4),\n",
    "    (df2['Red_cards'] == 2) & (df2['Yellow_cards'] < 4),\n",
    "    (df2['Red_cards'] == 1) & (df2['Yellow_cards'] >= 6),\n",
    "    (df2['Red_cards'] == 1) & (df2['Yellow_cards'] < 6),\n",
    "    (df2['Red_cards'] == 0) & (df2['Yellow_cards'] > 8),\n",
    "    (df2['Red_cards'] == 0) & (df2['Yellow_cards'].between(4, 8, inclusive='both')),\n",
    "    (df2['Red_cards'] == 0) & (df2['Yellow_cards'] < 4)\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    'High risk',\n",
    "    'Risky',\n",
    "    'High risk',\n",
    "    'Risky',\n",
    "    'High risk',\n",
    "    'Risky',\n",
    "    'Low risk'\n",
    "]\n",
    "\n",
    "# Create column names 'Risk_assessment' \n",
    "df2['Risk_assessment'] = np.select(conditions, labels, 'Not Classified')\n",
    "\n",
    "# Print the new column and cards \n",
    "print(df2[['Player', 'Yellow_cards', 'Red_cards', 'Risk_assessment']])\n",
    "\n",
    "# Remove rows where \"Risk_assessment\" is \"Not classified\" in-place\n",
    "df2.drop(df2[df2['Risk_assessment'] == 'Not Classified'].index, inplace=True)\n",
    "\n",
    "print(df2[\"Risk_assessment\"].unique())\n",
    "\n",
    "# Save the new full processed file \n",
    "df2.to_csv('NAC.csv', index =False )\n",
    "\n",
    "# Call the new fully pre-processed dataframe \n",
    "df3 = pd.read_csv(\"NAC.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Include all exploratory Data Analysis questions you studied in this section. This is related to the sufficient and good criteria of ILO 4.1 and 4.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start with EDA I did to create the new column(Risk assessment), then I will provide some of the codes I used for the EDA at the start of the block.\n",
    "\n",
    "When I started off with my idea I wasn't sure how I should categorize the players so I called some basic functions about the columns I wanted to use to get some basic information about them.\n",
    "I created a variable names 'cards' thaty contained all the red and yellow cars columns so that I didn't have to keep writing them out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which columns I wanted to get infromation from, for my case it would be the red and yellow cards\n",
    "cards = ['Red_cards', 'Red_cards_per_90', 'Yellow_cards', 'Yellow_cards_per_90']\n",
    "\n",
    "# Check the max and min for each column\n",
    "cards_max = df3[cards].max()\n",
    "cards_min = df3[cards].min()\n",
    "\n",
    "# Check the mean, median and modes for each column \n",
    "cards_mean = df3[cards].mean()\n",
    "cards_mode = df3[cards].mode()\n",
    "cards_median = df3[cards].median()\n",
    "\n",
    "# Calculate variance of cards\n",
    "cards_var = df3[cards].var()\n",
    "\n",
    "# Print them\n",
    "print(\"\\nThe maximum amount of each card that a player has gotten:\\n\",cards_max)\n",
    "print(\"\\nThe Minimum amount of each card that a player has gotten:\\n\",cards_min)\n",
    "print(\"\\nThe average amount of cards per player:\\n\",cards_mean)\n",
    "print(\"\\nThe median of cards:\\n\",cards_median)\n",
    "print(\"\\nThe mode of cards:\\n\",cards_mode)\n",
    "print(\"\\nThe variance of cards\\n\", cards_var)\n",
    "\n",
    "# Find the player with the most red cards\n",
    "player_most_red_cards = df3['Red_cards'].idxmax()\n",
    "most_red_cards = df3['Red_cards'].max()\n",
    "\n",
    "# Find the player with the most yellow cards\n",
    "player_most_yellow_cards = df3['Yellow_cards'].idxmax()\n",
    "most_yellow_cards = df3['Yellow_cards'].max()\n",
    "\n",
    "# Print or use the results as needed\n",
    "print(f\"The player with the most red cards is {player_most_red_cards} with {most_red_cards} red cards.\")\n",
    "print(f\"The player with the most yellow cards is {player_most_yellow_cards} with {most_yellow_cards} yellow cards.\")\n",
    "\n",
    "\n",
    "yellow_cards_18 = df3[df3['Yellow_cards'] == 18]\n",
    "\n",
    "# Get the count of players with 18 yellow cards\n",
    "num = yellow_cards_18.shape[0]\n",
    "\n",
    "print(\"Number of players with 18 Yellow Cards:\", num)\n",
    "\n",
    "# Assuming df3 is your DataFrame\n",
    "More_than_16 = df3[df3['Yellow_cards'] > 16]\n",
    "\n",
    "# Get the count of players with more than 14 yellow cards\n",
    "amount = More_than_16.shape[0]\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of players with more than 14 Yellow Cards:\", amount)\n",
    "\n",
    "# Frequency count for each category \n",
    "risk = df3['Risk_assessment'].value_counts()\n",
    "\n",
    "# Display the frequency counts\n",
    "print(\"Frequency counts for Risk Assessment:\", risk)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations \n",
    "The new cell is the EDA we did at the beginning of the block, I provided a couple that I found the most interesting. \n",
    "Further down by 'Visualizations' I provided the questions that I plotted.\n",
    "\n",
    "The first code that I provided is to answer the question \"Which country has the highest representation in the dataset in terms of player birthplace? First I had to count how many players there were per country. I used idxmax() to find which country has the highest amount of reprsentation, then I count up the amount of times that country came up.\n",
    "\n",
    "The second code I provided was to answer the question \"What is the distribution of player'sn positions across different teams?\". This was very simple to answer, I used \n",
    ".groupby() and specified my conditions which were \"Team\" and \"Position\" then I used \n",
    ".count() to count it all up \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your exploratory data analysis of the NAC data here. You can add Mark Down blocks (or output f-strings) to provide explanations to your code, alongside comments made in your code. \n",
    "\n",
    "# I have to count the number of players from each country\n",
    "country_count = df3['Birth_country'].value_counts()\n",
    "\n",
    "# I can use max() to see which country comes up the most for the \"Birth country\" column\n",
    "highest_rep_country = country_count.idxmax()\n",
    "highest_rep_count = country_count.max()\n",
    "\n",
    "print(f\"The country with the highest representation is {highest_rep_country} with {highest_rep_count} players\")\n",
    "\n",
    "team_position_count = df.groupby(\"Team\")[\"Position\"].count()\n",
    "print(\"The amount of players per team:\",(team_position_count))\n",
    "\n",
    "\n",
    "# Calculate mean and median of age \n",
    "average_age = df3[\"Age\"].mean()\n",
    "median_age = df3[\"Age\"].median()\n",
    "\n",
    "# Count the total amount of rows and columns in df \n",
    "df.shape\n",
    "\n",
    "\n",
    "print(\"The average age of players is:\", average_age)\n",
    "print(\"The median age of players is:\", median_age)\n",
    "\n",
    "# Get the amount of nun-numerical columns \n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Include all the visualizations you made in this section. This is related to the excellent criteria of ILO 4.2. Use the blocks below to enter the code for graphs you created with matplotlib (or seaborn, bokeh, or another visualization package). \n",
    "\n",
    "❗ If you would like to showcast your visualizations using streamlit, you need to hand in a seperate .py file for this. It is not possible to run streamlit code from a python notebook. Please note down below if you do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations \n",
    "The first plot was to answer the question \"How does the market value of players correlate with their age?\". From the correlation matrix you can see that the correlation is extremely week with the correlation co-efficient being 0.0061\n",
    "\n",
    "The second visualization showed the top 10 countries with the most amount of players\n",
    "\n",
    "The third visualization is the correlation between a player's height, weight, and goals. This showed that a player's height and weight have a pretty strong correlation with the correlation co-efficient being 0.83. There isn't a correlation between weight and goals or height and goal, with the correlation co-efficient being 0.064 and 0.065, respectively. While the correlation is a bit stronger than the first visualization it is still an extremely week one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size \n",
    "plt.figure(figsize=(12, 6))  \n",
    "\n",
    "# Yellow cards\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df3['Yellow_cards'], color='orange')\n",
    "plt.title('Distribution of Yellow Cards')\n",
    "plt.xlabel('Yellow Cards')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Red cards\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df3['Red_cards'], color='red')\n",
    "plt.title('Distribution of Red Cards')\n",
    "plt.xlabel('Red Cards')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style \n",
    "sns.set(style=\"whitegrid\") \n",
    "\n",
    "# Create chart\n",
    "plt.figure(figsize=(8, 6))  \n",
    "\n",
    "# Countplot to see the categories in \"Risk_assessment\"\n",
    "sns.countplot(x='Risk_assessment', data=df3)\n",
    "\n",
    "# Labels and titles \n",
    "plt.xlabel('Risk Assessment')\n",
    "plt.ylabel('Number of Players')\n",
    "plt.title('Number of Players in Each Risk Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Red_cards', data=df3, color='salmon')\n",
    "plt.title('Box Plot of Red Cards')\n",
    "plt.xlabel('Number of Red Cards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Yellow_cards', data=df3, color='salmon')\n",
    "plt.title('Box Plot of Yellow Cards')\n",
    "plt.xlabel('Number of Yellow Cards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add visualizations here that you made to present insights in the NAC data. Create a new codeblock for every graph. Add markdown blocks to describe your graphs where necessary.\n",
    "\n",
    "# make a correlation matrix and plot it \n",
    "correlation_matrix = df3[['Market_value', 'Age']].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()\n",
    "# the correlation is 0.0061, which means it has a very very week correlation. Basically non-existent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to show the top 10 countries with the most players \n",
    "# Specify top 10 \n",
    "top_countries = country_count.head(10)\n",
    "\n",
    "# Specify size \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar plot \n",
    "sns.barplot(x = top_countries.index, y=top_countries.values, palette= 'viridis')\n",
    "\n",
    "# Give titles \n",
    "plt.title('Top 10 countries with the most amount of players')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of players')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to create a correlation matrix that might have a good correlation\n",
    "# create and plot a correlation matrix\n",
    "correlation_matrix = df3[['Weight', 'Height', 'Goals' ]].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database and ETL\n",
    "\n",
    "Include all the python code and explanations on your RESTful API and database operations in this section. This is related to the excellent criteria of ILO 4.1.\n",
    "\n",
    "❗ These code you cannot showcast using the NAC data. Use the data provided for the homework and datalab preperation of these modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include your code here for for the API and ETL. This is not done on the NAC data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### Identifying basic Machine Learning applications.\n",
    "In the following subsection, show your understanding of each of the listed Machine Learning algorithms. Excecute these algorithms on the NAC dataset. This is related to the poor (and insufficient) criteria of ILO 5.0. \n",
    "\n",
    "❗Remember! All your package imports should be on top of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple machine learning modelling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "Simple machine learning modeling: my target variable is the risk assessment of players. I started of by using LabelEncoder() to encode Risk assessment as it is a non numerical column. After I defined my features and target variable, I chose the features based off of the correlation analysis I did at the bottom \"Correlation Analysis and Feature Selection\", I chose the top columns 8 with the highest correalation co-efficient, except the red and yellow cards. My target is of course the \"Risk_assessment\" column. After choosing my variables I used train_test_split to split my dataset. The test size i used was 20% as that is what i am used to.\n",
    "Update: I changed my test size to 0.40, I tried with different percentages but I found that most models had the same accuracy levels when I changed the test size between 0.20 and 0.40. One of the models had a better accuracy with the test size at 0.40 so I used it for both the splitting and testing sets.\n",
    "I used drop() to define my features, I deicided to drop the columns rather than define the ones I want to use because there are less columns to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'Risk_assessment' column\n",
    "label = LabelEncoder()\n",
    "df3['Risk_assessment'] = label.fit_transform(df3['Risk_assessment'])\n",
    "\n",
    "# Define features and target \n",
    "XX = df3[['Matches_played', 'Minutes_played', 'Shots', 'xA', 'Conceded_goals_per_90', 'Shots_against_per_90', 'xG_against_per_90', 'Save_rate,_%']]\n",
    "yy = df3['Risk_assessment']\n",
    "\n",
    "# Split the data \n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size=0.4, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    " I created a linear regression model using LinearRegression(), afterwards I trained the data using .fit(). I used predict() to make predictions on the testing data which is X_test, and named the predicted values y_pred. I used Mean squared error and r2 to evaluate the performance of the model, the MSE returned 0.63 and r2 return 0.01. The MSE measure the average squared difference between the predicted and actual values, the ideal value is 0, this means that with a MSE of 0.63 there are a good amount of errors in this model's prediction. This is further proved by the r2 score, r2 measures how well the model explains the variance in the target variable. The range for r2 is 0 to 1, with 0 meaning the model does not explain any variance, and 1 indicates a perfect fit. A score of 0.01 means that he model is not capturing much of the variability in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model \n",
    "linear_model.fit(XX_train, yy_train)\n",
    "\n",
    "# Predictions on the testing data\n",
    "yy_pred = linear_model.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(yy_test, yy_pred)\n",
    "r2 = r2_score(yy_test, yy_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R-squared Score: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "The logistic regression steps is a lot like the steps for linear regression. I created the logistic regression model using LogisticRegression() and trained the data using fit(). Like before I used predict() to make predictions using X_test and stored the predictions in y_pred. Then I evaluated the model, I used accucracy_score to check the accuracy of the predictions compared to the test. The accuracy score returned 0.61 or 61%, 61% is not bad especially when compared to the outcome of the linear regression model but it could be better. I also added in confusion matrix and classification report so I can get better insight, I will use this information when evaluating and comparing the performance of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Train the model \n",
    "logreg_model.fit(XX_train, yy_train)\n",
    "\n",
    "# Predictions on the testing data\n",
    "yy_pred = logreg_model.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(yy_test, yy_pred)\n",
    "conf_matrix = confusion_matrix(yy_test, yy_pred)\n",
    "class_report = classification_report(yy_test, yy_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations \n",
    "I chose to use Random Forest for my tree based model because there is already a Gradient Boosting Tree section below and  Random Forest tends to produce more accurate predictions than a single decision tree. \n",
    "I started of like all the other models, I started by creating the Random Forest model with RandomForestClassifier. I trained the model using fit() and make predictions using predict(). I used accucarcy_score to calculate the accuracy of the model which is about 0.64 or 64%, I also added a classification report and Confusion Matrix for my own insight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the non-numerical data\n",
    "le = LabelEncoder()\n",
    "for col in XX.columns:\n",
    "    if XX[col].dtype == 'object':\n",
    "        XX[col] = le.fit_transform(XX[col])\n",
    "\n",
    "# Split the data \n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# Create Random Forest Classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions \n",
    "yy_pred = rf_model.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(yy_test, yy_pred)\n",
    "conf_matrix = confusion_matrix(yy_test, yy_pred)\n",
    "classification_rep = classification_report(yy_test, yy_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Trees and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "I used GradientBoostingClassifier() to create the gradient boosting classifier. I used fit() to train the model and predict() to make predictions based on the test set and stored it in yy_gb. Lastly, I calculated the accuracy and the confusion matrix. The accuracy is the highest one I've gotten with the different models, which is about 65% (0.65). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Train the model\n",
    "gb.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions\n",
    "yy_gb = gb.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(yy_test, yy_gb)\n",
    "conf_matrix_gb = confusion_matrix(yy_test, yy_gb)\n",
    "classification_rep_gb = classification_report(yy_test, yy_gb)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_gb)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_gb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "We didn't get SVM in our DataLab(Prep) so I Had to google what it is first, the steps are the same as the previous ones. Like always I started with creating SVM, trained the model and made predictions. The accuracy is 0,64 which is higher than the random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Train the model\n",
    "svm.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions \n",
    "yy_svm = svm.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(yy_test, yy_svm)\n",
    "conf_matrix_svm = confusion_matrix(yy_test, yy_svm)\n",
    "classification_rep_svm = classification_report(yy_test, yy_svm)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised learning with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed to combine the the test and training sets as it was inconsistent. I used LabelEncoder to econcode the training and testing sets like I did above but it kept giving me an error, with the help of my sister I combined the two sets encoded them and then split the combined sets back into their original training and testing sets. To ensure that the features are on a similar scale I used StandardScaler() to standardize my data. I had different codes before which returned something totally different so I asked Edirlei to help me, we decided on using 3 clusters. fit_predict was used to train the model and predict is used the test set. We created a new column named \"Clusters' and called the top rows of clusters using head(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sets \n",
    "combined_df = pd.concat([XX_train, XX_test])\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in combined_df.columns:\n",
    "    if combined_df[col].dtype == 'object':\n",
    "        combined_df[col] = le.fit_transform(combined_df[col])\n",
    "\n",
    "# Split the sets back\n",
    "XX_train_cluster = combined_df.iloc[:len(XX_train)]\n",
    "XX_test_cluster = combined_df.iloc[len(XX_train):]\n",
    "\n",
    "# Standardize the data \n",
    "scaler = StandardScaler()\n",
    "XX_train_cluster_scaled = scaler.fit_transform(XX_train_cluster)\n",
    "XX_test_cluster_scaled = scaler.transform(XX_test_cluster)\n",
    "\n",
    "# k-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  \n",
    "edirlei_train = kmeans.fit_predict(XX_train_cluster_scaled)\n",
    "edirlei_test = kmeans.predict(XX_test_cluster_scaled)\n",
    "\n",
    "# Add cluster assignments as new columns\n",
    "XX_train_cluster[\"Clusters\"] = edirlei_train\n",
    "XX_test_cluster[\"Clusters\"] = edirlei_test\n",
    "\n",
    "print(XX_test_cluster.head())\n",
    "kmeans.cluster_centers_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis and Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations \n",
    "I started with this correlation from the beginning to help me choose the features I used for the previous models. \n",
    "I started with LabelEncoder() to encode all the non-numerical variables, I used .corr() to create the correlation. I wanted to know whic variables had the highest correlation to my target, so I set the target as \"Risk_assessment\" and sorted it by using ascending= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for col in df3.columns:\n",
    "    if df3[col].dtype == 'object':\n",
    "        df3[col] = label_encoder.fit_transform(df3[col])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation = df3.corr()\n",
    "\n",
    "# Specify target\n",
    "target = correlation['Risk_assessment']\n",
    "\n",
    "# Sort features from highest correlation\n",
    "features = target.abs().sort_values(ascending=False)\n",
    "\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "The accuracy for the models weren't as high as I had hoped, my highest was Gradient Boosting Trees with 65%. I'm going to use every single column except 'Risk_assessment', 'Red_cards', 'Yellow_cards', 'Red_cards_per_90', 'Yellow_cards_per_90', I'm dropping these columns because I used them to determine the risk level. I want my model to predict the risk level based off of other features. By using every variable I'm hoping to increase the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable, I used this for the rest of the models \n",
    "yy = df3['Risk_assessment']\n",
    "XX = df3.drop(['Risk_assessment', 'Red_cards', 'Yellow_cards', 'Red_cards_per_90', 'Yellow_cards_per_90'], axis=1)\n",
    "\n",
    "\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍️ I chose the features above because ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance of the model\n",
    "\n",
    "In the following subsection include your Python code on how you evaluated your chosen model(s). This is related to the sufficient criteria of ILO 5.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "\n",
    "After talking to different mentors, I concluded that we don't have to evaluate every single model. They told me to choose either the most relevent ones or the ones that provided the highest results, I chose Gradient Boosting Trees and Random Forest as they Provided the highest results and are both classification models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the non-numerical data\n",
    "le = LabelEncoder()\n",
    "for col in XX.columns:\n",
    "    if XX[col].dtype == 'object':\n",
    "        XX[col] = le.fit_transform(XX[col])\n",
    "        \n",
    "# Split the data \n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "rf.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions \n",
    "yy_pred = rf.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(yy_test, yy_pred)\n",
    "conf_matrix = confusion_matrix(yy_test, yy_pred)\n",
    "classification_rep = classification_report(yy_test, yy_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Train the model\n",
    "gb.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions\n",
    "yy_gb = gb.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(yy_test, yy_gb)\n",
    "conf_matrix_gb = confusion_matrix(yy_test, yy_gb)\n",
    "classification_rep_gb = classification_report(yy_test, yy_gb)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_gb)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_gb)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "0 = high risk, 1 = low risk, 2 = risky\n",
    "Class 1 (low risk) has the highest precision and recall, which means that the models are good at predicting low risk players. Both models have a very low recall for class 0, meaning that  there is a high number of false negatives. Random Forest has a higher precision for class 2 (risky) but Gradient Boosting Trees has a slightly better balance (f1-score). Based off of the classification report, Gradient Boosting Trees perform slightly better than the Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the performance of the model\n",
    "\n",
    "In the following subsection include your Python code on how you improved your chosen model(s). This is related to the good criteria of ILO 5.0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations \n",
    "\n",
    "Firstly, I'm going to use cross_val_score to check the consistency of both models. Secondly, I used RandomizedSearchCV() hyperparameters for the models. The search I did for the random forest returned positive results (max_depth= 20, min_samples_leaf= 1, min_samples_split= 10, n_estimators= 150) I entered this information into the random forest model and got an accuracy ok 69%. When I didn't add any hyperparameters it was also 69%. The accuracy got a bit better it went from 0.697 to 0.699, it does not make a big difference but adding hyperparameters does add some value to my model. It can ensure reproducibility and can perform more consistently if new data were to be added in the dataset. For my Gradient Boosting forest I also performed a random search, which is the code that I changed to markdown because it ran for hours. After adding the parameters the accuracy decreased ever so slightly, I think it's a bit of a personal preference. I prefer adding parameters even tho it decreased the accuracy a bit to ensure reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "cv_rf = cross_val_score(rf, XX, yy, cv = 5)  \n",
    "cv_gb = cross_val_score(gb, XX, yy, cv = 5)\n",
    "\n",
    "print(\"Cross validation scores for Random Forest:\", cv_rf)\n",
    "print(\"Cross validation scores for Gradient Boosting Trees:\", cv_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Perform random search on the training data\n",
    "search.fit(XX_train, yy_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_rf = search.best_params_\n",
    "print(best_params_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the non-numerical data\n",
    "le = LabelEncoder()\n",
    "for col in XX.columns:\n",
    "    if XX[col].dtype == 'object':\n",
    "        XX[col] = le.fit_transform(XX[col])\n",
    "        \n",
    "# Split the data \n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create Random Forest Classifier\n",
    "rf = RandomForestClassifier(max_depth= 20, min_samples_leaf= 1, min_samples_split= 10, n_estimators= 150)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions \n",
    "yy_pred = rf.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(yy_test, yy_pred)\n",
    "conf_matrix = confusion_matrix(yy_test, yy_pred)\n",
    "classification_rep = classification_report(yy_test, yy_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(gb, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Perform random search on the training data\n",
    "search.fit(XX_train, yy_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_gb = search.best_params_\n",
    "print(best_params_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier(max_depth= 20, min_samples_leaf= 1, min_samples_split= 10, n_estimators= 150)\n",
    "\n",
    "# Train the model\n",
    "gb.fit(XX_train, yy_train)\n",
    "\n",
    "# Make predictions\n",
    "yy_gb = gb.predict(XX_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(yy_test, yy_gb)\n",
    "conf_matrix_gb = confusion_matrix(yy_test, yy_gb)\n",
    "classification_rep_gb = classification_report(yy_test, yy_gb)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_gb)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_gb)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep_gb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps I took to imrpove my model, I started by changing the features. Instead of choosing which features I wanted to use, I dropped the ones I didn't want to use (which is the ones I myself used to determine the risk level). The accuracy increased after I changed the features, afterwards I used cross validation to check the consistency of both models. I did a Random Grid Search for both models, after adding the parameters to their respective models I observed that it did not have a big impact on either of the accuracy score. While that is not ideal it is also not bad, like I mentioned above parameters are valuable to the models as it ensures reproducibilty and performs more consistently "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n",
    "Test Set Accuracy: 0.6928719502471695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best model\n",
    "\n",
    "In the following subsection reflect on the most appropriate machine learning model. This is related to the excellent criteria of ILO 5.0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations \n",
    "I concluded that the Random Forest model is the best model for me. While the accuracy score is slightly lower than the one of Gradient Boosting Forest, there are many other considerations to take in mind. From the cross validation you can see that the Random Forest is way more consistent and the average of the scores is also higher, which means that the model is more reliable and stable. Furthermore, Random Forest models are a lot more computantionally effecient it took me almost 4 hours to perform a random search on the Gradient Boost model, in comparisson to 2 minutes for Random Forest. So while the accuracy is important it is not the sole determination for the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here for comparing your models. Describe in the markdown below why the model you chose is the best model.\n",
    "# Perform cross-validation\n",
    "cv_rf = cross_val_score(rf, XX, yy, cv = 5)  \n",
    "cv_gb = cross_val_score(gb, XX, yy, cv = 5)\n",
    "\n",
    "print(\"Cross validation scores for Random Forest:\", cv_rf)\n",
    "print(\"Cross validation scores for Gradient Boosting Trees:\", cv_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross validation score mean, Random Forest:\", cv_rf.mean())\n",
    "print(\"Cross vaildation score mean, Gradient Boost:\",cv_gb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍️ The model is chose is the best because ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra and Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following subsection, provide the related evidences for ILO7.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment for \"Elementary Operation on Matrices\"\n",
    "\n",
    "This task is associated with the 'Poor' criterion of ILO 7.0. You can find the assignment [here](https://adsai.buas.nl/Study%20Content/Advanced%20Python/AssignElemOpe.html).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please provide the related link to the PDF file for Task 1 of assignment on elementary operations on matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide the link to the assignment on elementary operations on matrices here\n",
    "https://github.com/BredaUniversityADSAI/2023-24b-fai1-adsai-CelineWu231265/blob/main/Deliverables%20/ILO%207%20/EleOpeMat_231265.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please provide your code for Task 2 of assignment on elementary operations on matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the transpose of matrices A and B\n",
    "#To compute the transpose of a matrix you can use either numpy.transpose function or .T method .\n",
    "# THe first list is the first row of the matrix and the second list is the seconf row\n",
    "import numpy as np\n",
    "\n",
    "Matrix_A = [[3, -5],[-2, 7]]\n",
    "Matrix_A_transpose = np.transpose(Matrix_A)\n",
    "print(\"Matrix A transpose:\")\n",
    "print(Matrix_A_transpose)\n",
    "\n",
    "Matrix_B = [[2, -3, 4], \n",
    "            [-5, 6, 7], \n",
    "            [-8, 9, 1]]\n",
    "Matrix_B_transpose = np.transpose(Matrix_B)\n",
    "print(\"Matrix B transpose:\")\n",
    "print(Matrix_B_transpose)\n",
    "\n",
    "# Compute the element-wise product of matrices A and B \n",
    "# The matrices are both 3 x 3 so I'd have to have 3 lists per variable, I need 2 variables because there's matrix A and B \n",
    "# I'm not sure why i have to use .array here when I didn't above\n",
    "array1 = np.array ([[3, 2, -1], [-2, 7 ,4], [1, 6, 8]])\n",
    "array2 = np.array ([[2, -3, -4], [-5, -6, 7], [-8, 9, 1]])\n",
    "\n",
    "element_wise = np.multiply(array1, array2)\n",
    "print(\"Element-wise product of matrices A and B:\")\n",
    "print(element_wise)\n",
    "\n",
    "# Compute the matrix product of matrices A and B \n",
    "print(\"Matrix product of matrices A and B:\")\n",
    "print(np.dot(array1, array2))\n",
    "\n",
    "# Compute the inversion of matrices A and B\n",
    "array1 = np.array([[3, 2, -1], [-2, 7, 4], [1, 6, 8]])\n",
    "array2 = np.array([[2, -3, -4], [-5, -6, 7], [-8, 9, 1]])\n",
    "\n",
    "# Compute the inverse of array1\n",
    "inverse = np.linalg.inv(array1)\n",
    "\n",
    "# Multiply the inverse by array2 to get the result\n",
    "result = np.dot(inverse, array2)\n",
    "\n",
    "print(\"Matrix Inverse:\")\n",
    "print(inverse)\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication \n",
    "\n",
    "# (A.T).T = A\n",
    "# define the matrices \n",
    "# verify the properties listed in the task \n",
    "# check whether the properties are true or not using np.array_eual\n",
    "A = np.array([[3,2,-1],[-2,7,4],[1,6,8]])\n",
    "B = np.array([[-1,2,3],[5,-4,9],[-7,8,6]])\n",
    "C = np.array([[-5,4,9],[6,1,3],[7,2,-8]])\n",
    "\n",
    "First = np.array_equal((A.T).T, A)\n",
    "\n",
    "print(\"(A.T).T is equal to A:\", First)\n",
    "\n",
    "#  A + B = B + A\n",
    "Second = np.array_equal(A + B, B + A)\n",
    "print(\"A + B is equal to B + A:\", Second)\n",
    "\n",
    "# A + (B + C) = (A + B) + C\n",
    "Third = np.array_equal (A + (B + C), (A + B) + C)\n",
    "print (\"A + (B + C) is equal to (A + B) + C:\", Third)\n",
    "\n",
    "# (A + B).T = A.T + B.T\n",
    "Fourth = np.array_equal ((A + B).T, A.T + B.T)\n",
    "print(\"(A + B).T is equal to A.T + B.T:\", Fourth)\n",
    "\n",
    "# AB != BA\n",
    "Fifth = np.array_equal (A * B, B * A)\n",
    "print(\"AB is not equal to BA:\", Fifth)\n",
    "\n",
    "# A(BC) = (AB)C\n",
    "Sixth = np.array_equal(A * (B * C), (A * B) * C)\n",
    "print (\"A(BC) is equal to (AB)C\", Sixth)\n",
    "\n",
    "# A(B + C) = AB + AC\n",
    "Seventh = np.array_equal(A * (B + C), A * B + A * C)\n",
    "print(\"A(B+C) is equal to AB + AC:\", Seventh )\n",
    "\n",
    "# (AB).T = B.T A.T\n",
    "Eighth = np.array_equal((A * B).T, B.T * A.T)\n",
    "print(\"(AB).T is equal to B.T * A.T:\", Eighth)\n",
    "\n",
    "# (AB)^-1 = B^-1 * A^-1\n",
    "Ninth = np.array_equal((A * B)^-1, B^-1 * A^-1 )\n",
    "print(\"(AB)^-1 is equal to B^-1 * A^-1:\", Ninth)\n",
    "\n",
    "# (A.T)^-1 = (A^-1).T\n",
    "Tenth = np.array_equal((A.T)^-1, (A^-1).T)\n",
    "print(\"(A.T)^-1 is equal to (A^-1).T:\", Tenth)\n",
    "\n",
    "# (𝛼 + 𝛽)A = 𝛼A + 𝛽A\n",
    "alpha = 2\n",
    "beta = 3\n",
    "eleventh = np.array_equal((alpha + beta)* A, alpha * A + beta * B)\n",
    "print (\"(𝛼 + 𝛽)A is equal to 𝛼A + 𝛽A:\", eleventh)\n",
    "\n",
    "# 𝛼(A + B) = 𝛼A + 𝛼B\n",
    "twelve = np.array_equal(alpha * (A + B), alpha * A + alpha * B)\n",
    "print (\"𝛼(A + B) is equal to 𝛼A + 𝛼B:\", twelve)\n",
    "\n",
    "# (𝛼A)^-1 = 𝛼^-1 * A^-1\n",
    "thirteenth = np.array_equal((alpha * A)^-1, alpha^-1 * A^-1)\n",
    "print(\"(𝛼A)^-1 is equal to 𝛼^-1 * A^-1:\", thirteenth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment for  \"Linear Regression Model Using Normal Equations\"\n",
    "\n",
    "This task is associated with the ‘Poor' criterion of ILO 7.0. You need to complete the assignment on linear regression using normal equations at the middle of [this page](https://adsai.buas.nl/Study%20Content/Advanced%20Python/6.AdvancedNumPyMatPlotlib.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1.1\n",
    "# Coefficients\n",
    "A = np.array([\n",
    "    [1, 3, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, -1, 1]\n",
    "])\n",
    "\n",
    "# Right-hand side values\n",
    "B = np.array([9, 10, 8])\n",
    "\n",
    "# Solve the system of equations\n",
    "solution = np.linalg.solve(A, B)\n",
    "\n",
    "print(\"Solution for task 1.1\")\n",
    "print(\"1 =\", solution[0])\n",
    "print(\"2 =\", solution[1])\n",
    "print(\"3 =\", solution[2])\n",
    "\n",
    "# Task 1.2\n",
    "# Coefficients \n",
    "A = np.array([\n",
    "    [5, 6, -7, 1],\n",
    "    [1, 2, 3, 4],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, -3, 0, 0]\n",
    "])\n",
    "\n",
    "# Right-hand side values\n",
    "B = np.array([8, 7, 9, 12])\n",
    "\n",
    "# Solve the system of equations\n",
    "solution = np.linalg.solve(A, B)\n",
    "\n",
    "print(\"Solution for task 1.2\")\n",
    "print(\"1 =\", solution[0])\n",
    "print(\"2 =\", solution[1])\n",
    "print(\"3 =\", solution[2])\n",
    "print(\"4 =\", solution[3])\n",
    "\n",
    "# Task 2 \n",
    "np.random.seed(1358)\n",
    "\n",
    "n_sample = 10\n",
    "x = np.linspace(1, 5, n_sample)\n",
    "e = 0.1 * np.random.randn(n_sample)\n",
    "\n",
    "y = 2 * x + 3 + e\n",
    "\n",
    "X = np.vstack([np.ones_like(x), x]).T  # Add a column of ones for the intercept\n",
    "theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "theta0, theta1 = theta[0], theta[1]\n",
    "\n",
    "print(\"Theta0 (intercept):\", theta0)\n",
    "print(\"Theta1 (slope):\", theta1)\n",
    "\n",
    "# Task 3 \n",
    "np.random.seed(1358)\n",
    "\n",
    "n_sample = 30\n",
    "x = np.linspace(1, 10, n_sample)\n",
    "e = 0.2 * np.random.randn(n_sample)\n",
    "\n",
    "y = 3 + 2 * x + 7 * x**2 + e\n",
    "\n",
    "X = np.vstack([np.ones_like(x), x, x**2]).T\n",
    "\n",
    "theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "theta0, theta1, theta2 = theta[0], theta[1], theta[2]\n",
    "\n",
    "print(\"Theta0 (intercept):\", theta0)\n",
    "print(\"Theta1 (slope for x):\", theta1)\n",
    "print(\"Theta2 (slope for x^2):\", theta2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment for \"Calculus for Machine Learning\"\n",
    "\n",
    "This task is associated with the \"Insufficient\" criterion in ILO 7.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to complete with the [Differential Calculus](https://www.khanacademy.org/math/differential-calculus) course in Khan Academy and provide a link to the PDF file of certificate of completion you have put in your personal GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khan academy screenshot links\n",
    "https://github.com/BredaUniversityADSAI/2023-24b-fai1-adsai-CelineWu231265/blob/15da3dfe8b66d66c5b2a551fc8f9f5775ddea632/Deliverables%20/ILO%207%20/CalMacLea2_231265.png\n",
    "https://github.com/BredaUniversityADSAI/2023-24b-fai1-adsai-CelineWu231265/blob/15da3dfe8b66d66c5b2a551fc8f9f5775ddea632/Deliverables%20/ILO%207%20/CalMacLea_231265.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment for \"DataLab: Python for Symbolic Mathematics\"\n",
    "\n",
    "This task is associated with the \"Insufficient\" criterion in ILO 7.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to complete all the DataLab tasks (Tasks 1-5) at the end of [this page](https://adsai.buas.nl/Study%20Content/Advanced%20Python/28.SymbolicMathematicsDataLab.html). Provide your codes in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols\n",
    "import sympy\n",
    "# Define symbolic variable\n",
    "x, y = symbols('x y')\n",
    "\n",
    "# Definition of the expression\n",
    "ex1 = 2 * x**2 -x * y + 3\n",
    "ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = (x * ex1 + (2 * x + y)) / (x**2 + y)\n",
    "ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Eq, solve\n",
    "from sympy import expand\n",
    "expand(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.evalf(subs={x:-2, y:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables\n",
    "x, y = symbols('x y')\n",
    "\n",
    "# Define the system of equations\n",
    "equation1 = Eq(2*x + y, 5)\n",
    "equation2 = Eq(x - 2*y, 15)\n",
    "\n",
    "# Define the system of equations\n",
    "system_of_equations = [equation1, equation2]\n",
    "\n",
    "# Solve the system of equations\n",
    "solution = solve(system_of_equations, (x, y))\n",
    "\n",
    "print(\"Solution:\", solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Eq, solve, ln\n",
    "\n",
    "# Define the variable\n",
    "equation = Eq(2*x + 5, 11)\n",
    "\n",
    "# Solve the equation\n",
    "solution = solve(equation, x)\n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit Computation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import limit, symbols\n",
    "from sympy import sin\n",
    "from sympy import diff, cos, cot\n",
    "\n",
    "# Define the function\n",
    "f = sin(x) / x\n",
    "\n",
    "# calculate the limit as x approaches 0\n",
    "lim_result = limit(f, x, 0)\n",
    "lim_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivative Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variable \n",
    "x = symbols('x')\n",
    "\n",
    "# Define the function\n",
    "f = x**3 + 3 * x**2 + sin(x)\n",
    "\n",
    "# Calculate the derivative\n",
    "der_f = diff(f, x)\n",
    "\n",
    "der_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integral Computation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "# Define the function\n",
    "f = x*sin(x)\n",
    "\n",
    "# Compute the indefinite integral\n",
    "indefinite_integral = integrate(f,x)\n",
    "indefinite_integral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "# Define the function\n",
    "f = cos(x)\n",
    "\n",
    "# Compute the definite integral\n",
    "definite_integral = integrate(f, (x,0,pi/2)) \n",
    "definite_integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taylor Series (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "f = exp(x)\n",
    "\n",
    "# Compute the terms of the Taylor series\n",
    "taylor_series = f.series(x, 0, 4).removeO()\n",
    "\n",
    "# Display the terms of the Taylor series\n",
    "taylor_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Squares Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = [(1,2), (2,3), (3,4), (4,5)]\n",
    "\n",
    "# Variables for the linear equation: y = mx + c\n",
    "m, c = sp.symbols('m c')\n",
    "\n",
    "# Sum of squared differences between observed and predicted y-values\n",
    "error = sum((m * x + c - y)**2 for x, y in data_points)\n",
    "\n",
    "# Finding partial derivatives of the error function with respect to m and c\n",
    "partial_m = sp.diff(error, m)\n",
    "partial_c = sp.diff(error, c)\n",
    "\n",
    "# Solving the system of equations to minimise the error (least squares solution)\n",
    "solution = sp.solve((partial_m, partial_c), (m, c))\n",
    "\n",
    "best_fit_m, best_fit_c = solution[m], solution[c]\n",
    "best_fit_m, best_fit_c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1358)\n",
    "x = np.linspace(-3,3, 100)\n",
    "y_true = 0.3 * x**4 -0.1 * x**3 - 2* x**2 - 0.8*x\n",
    "y = y_true + np.random.randn(len(x))\n",
    "plt.plot(x,y_true, '--')\n",
    "plt.plot(x,y, '.')\n",
    "plt.xlabel('x', size=14)\n",
    "plt.ylabel('y', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = [(1,2), (2,3), (3,4), (4,5)]\n",
    "\n",
    "#Defining the symbols\n",
    "a1, a0 = sp.symbols('a1 a0')\n",
    "ex1 = [a1 * x + a0 - y for x, y in data_points]\n",
    "\n",
    "# Solving the system of equations to minimise the error (least squares solution)\n",
    "solution = sp.linsolve(ex1, a1, a0)\n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = [(1,2), (2,3), (3,4), (4,5)]\n",
    "\n",
    "#Defining the symbols\n",
    "a2, a1, a0 = sp.symbols('a2 a1 a0')\n",
    "ex2 = [a2 * x ** 2 + a1 * x + a0 - y for x, y in data_points]\n",
    "\n",
    "# Solving the system of equations to minimise the error (least squares solution)\n",
    "solution = sp.linsolve(ex2, a2, a1, a0)\n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = [(1,2), (2,3), (3,4), (4,5)]\n",
    "\n",
    "#Defining the symbols\n",
    "a3, a2, a1, a0 = sp.symbols('a3 a2 a1 a0')\n",
    "ex3 = [a3 * x ** 3 + a2 * x ** 2 + a1 * x + a0 - y for x, y in data_points]\n",
    "\n",
    "# Solving the system of equations to minimise the error (least squares solution)\n",
    "solution = sp.linsolve(ex3, a3, a2, a1, a0)\n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = [(1,2), (2,3), (3,4), (4,5)]\n",
    "\n",
    "#Defining the symbols\n",
    "a4, a3, a2, a1, a0 = sp.symbols('a4 a3 a2 a1 a0')\n",
    "ex4 = [a4 * x ** 4 + a3 * x ** 2 + a2 * x ** 2 + a1 * x + a0 - y for x, y in data_points]\n",
    "\n",
    "# Solving the system of equations to minimise the error (least squares solution)\n",
    "solution = sp.linsolve(ex4, a4, a3, a2, a1, a0)\n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = [(1,2), (2,3), (3,4), (4,5)]\n",
    "\n",
    "#Defining the symbols\n",
    "a5, a4, a3, a2, a1, a0 = sp.symbols('a5 a4 a3 a2 a1 a0')\n",
    "ex5 = [a5 * x ** 5 + a4 * x ** 4 + a3 * x ** 3 + a2 * x ** 2 + a1 * x + a0 - y for x, y in data_points]\n",
    "\n",
    "# Solving the system of equations to minimise the error (least squares solution)\n",
    "solution = sp.linsolve(ex5, a5, a4, a3, a2, a1, a0)\n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "\n",
    "exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "# I did not put y = or - y at the end of the equation as this made no difference\n",
    "ex1 = x**2 + 2 * x + 1\n",
    "\n",
    "# Caluclating the derivative\n",
    "der_ex1 = diff(ex1, x)\n",
    "der_ex1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "# Define the function\n",
    "ex2 = (3 * x - 5)** 3\n",
    "\n",
    "# Caluclating the derivative\n",
    "der_ex2 = diff(ex2, x)\n",
    "der_ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "# Define the function\n",
    "ex3 = sqrt(x - 1)** 2 - (x ** 2 + 1)** 4\n",
    "\n",
    "# Caluclating the derivative\n",
    "der_ex3 = diff(ex3, x)\n",
    "der_ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "# Define the function\n",
    "ex4 = 7 * cot(x) - 8 * cos(x)\n",
    "\n",
    "# Calculating the derivative\n",
    "der_ex4 = diff(ex4, x)\n",
    "der_ex4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "ex5 = x - ln(x) + 7\n",
    "\n",
    "# Calculating the derivative\n",
    "der_ex5 = diff(ex5, x)\n",
    "der_ex5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, e = symbols('x e')\n",
    "\n",
    "ex6 = -10 * e ** x + 5 ** x + x/5\n",
    "\n",
    "# Calculating the derivative\n",
    "der_ex6 = diff(ex6, x, e)\n",
    "der_ex6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "ex7 = (2 * sin(x)) / (sin(x) - cos(x))\n",
    "ex7   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "\n",
    "ex8 = (x ** 2 * ln(x)) / (1 - tan(x))\n",
    "\n",
    "# Calculating the derivative\n",
    "der_ex8 = diff(ex8, x)\n",
    "der_ex8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment for \"Multivariable Calculus\"\n",
    "\n",
    "This task is associated with the \"Insufficient\" criterion in ILO 7.0. You need to complete the assignments 1-4 at the end of [this page](https://adsai.buas.nl/Study%20Content/Advanced%20Python/27.MultivariableCalculus.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a link to a PDF file, for assignments 1-3 in the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A link to a PDF file for assignments 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your code  for assignment 4 in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for assignment 4 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignments for \"Optimization Algorithms\"\n",
    "\n",
    "This task is associated with the \"Sufficient\" criterion in ILO 7.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the assignments at the end of [this page](https://adsai.buas.nl/Study%20Content/Advanced%20Python/29.OptimizationAlgorithms.html). Then put your code in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignments for \"DataLab: Linear Regression with Gradient Descent\"\n",
    "\n",
    "This task is associated with the \"Good\" and \"Excellent\" criteria in ILO 7.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the assignment at the end of [this page](https://adsai.buas.nl/Study%20Content/Advanced%20Python/30.LinearRegressionGradientDescentDataLab.html). Then put your code in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
